## 神经网络和深度学习 ##

### Note1 ###

**单个神经元**

**传递函数**：

常用的：阶梯函数（step），符号函数（sgn），线性函数（Linear），饱和线性函数（Ramp），对数S型函数（Sigmoid），双曲正切S型函数（Tanh）。

**感知机**：

感知机是最简单的神经网络。

>Neuroph:基于Java的神经网络框架

感知机无法解决XOR问题（可以解决AND和OR问题）。

>线性不可分是导致不能解决XOR问题的原因，而AND和OR则是线性可分的问题

**多层神经网络**

XOR问题可以通过在单层神经网络多加一层，并且利用Back-Propagating（BP）算法来解决。

1、感知器

双层神经网络模型，输入层和计算单元。

2、多层神经网络（前馈神经网络）

3、计算单元 

任意输入，单一输出。

4、层

### Note2 ###

  - 监督学习
  - 非监督学习
  - 强化学习（Reinforcement Learning）
  回报函数，无label，本质是马尔科夫决策过程，最终目的是决策过程中整体回报函数期望最优	。

深度学习是神经网络的一大分支，深度学习的基本结构是深度神经网络。

**特征**

人类视觉系统提取的过程是由：Retina->V1->V2->V4，高级表达是由低级表达组成的。

1、特征粒度

2、浅层特征

复杂图形是由基本图形构件组成。类似基

3、结构性特征

Retina->像素(pixls)

V1->边缘(edges)

V2->构件(object parts)

V4->物体(object models)

**浅层学习和深层学习**

浅层学习：多层感知机，SVM，Boosting，Logistics Regression
。单个隐层或没有隐层。


深层学习：多个隐层。Hinton提出的（Deep Belief Network）DBN
划时代。其中重要的几个原则

>  - 非监督学习被用来预训练各个层
>  - 非监督学习在之前学习到的层次之上，一次只学习一个层次，每个层次学习的结果作为下一个层次的输入
>  - 用监督学习来调整层之间的权重。

**深度学习和神经网络**

>BP算法：神经网络的训练

>    - 信号正向传播
>    - 误差反向传播

问题在于梯度稀疏，误差校正越来越小从顶至下；收敛局部最小值。

 
### Note3 ###

**深度学习常用方法**

自编码器

有监督微调：只调整最后的分类器；调整整个系统。

栈式自编码器：提供预训练方法初始化网络权重。

限制玻尔兹曼机

1、生成模型和概率模型

   - 决策函数和条件概率分布 可以互相转化。



